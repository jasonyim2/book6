{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 번역서 03.4 부분의 4. memory_key_padding_mask 내용은 아래 코드에서 Let's Declare Model 부분의 일부를 참조하세요."
      ],
      "metadata": {
        "id": "O4S2u-KbzuH7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 원서의 깃허브에서 제공하는 코드는 원서의 내용보다 훨씬 방대합니다.\n",
        "# 이에 따라, 원서 본문 및 번역번 본문에서는 깃허브 제공 코드의 일부분만 설명하고 있습니다.\n",
        "# 이는 타 챕터에도 적용됩니다."
      ],
      "metadata": {
        "id": "SSTfPTBjU-ol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 원서 번역 시점에서 호환되는 torch 및 torchtext 조합 설치\n",
        "# 이 다음 코드 불록에서 필요함\n",
        "# 런타임 3분 소요\n",
        "!pip install torch==2.0.1+cu118 torchtext==0.15.2 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# 이 코드를 실행 후 코랩 메뉴 [런타임] > [세션 다시 시작](restart the session)을 실행해야 함"
      ],
      "metadata": {
        "id": "dFBbOvGEzzwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install torch\n",
        "!pip install torchtext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "564EILtqVxfe",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1735158615313,
          "user_tz": -540,
          "elapsed": 22483,
          "user": {
            "displayName": "Jason SJ Yim",
            "userId": "00695299170620821850"
          }
        },
        "outputId": "558c3d40-5c9f-4ce3-ae27-0406ab40a5a7",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.27.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.31.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (18.1.8)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.10/dist-packages (0.15.2+cpu)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.32.3)\n",
            "Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.0.1+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext) (1.26.4)\n",
            "Requirement already satisfied: torchdata==0.6.1 in /usr/local/lib/python3.10/dist-packages (from torchtext) (0.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext) (3.1.4)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext) (2.0.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.6.1->torchtext) (2.2.3)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchtext) (3.31.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchtext) (18.1.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1->torchtext) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->torchtext) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#역자 추가 코드"
      ],
      "metadata": {
        "id": "VnvuiH8uMZ9a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# 랜덤 시드 설정\n",
        "torch.manual_seed(0)\n",
        "\n",
        "# 파라미터 정의\n",
        "num_embeddings = 10 # 어휘(vocabulary) 개수\n",
        "embedding_dim = 3   # 임베딩 벡터 차원\n",
        "\n",
        "# 임베딩 층\n",
        "embedding = nn.Embedding(\n",
        "    num_embeddings=num_embeddings, embedding_dim=embedding_dim)\n",
        "input_tokens = torch.tensor([1, 5])\n",
        "output_embeddings = embedding(input_tokens)\n",
        "print(output_embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YLUUGOFMZFL",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1735158635106,
          "user_tz": -540,
          "elapsed": 4785,
          "user": {
            "displayName": "Jason SJ Yim",
            "userId": "00695299170620821850"
          }
        },
        "outputId": "1de28596-c7e5-424c-e37a-fb8d93b8ece8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.4339,  0.8487,  0.6920],\n",
            "        [-0.1116, -0.6136,  0.0316]], grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Text Classification"
      ],
      "metadata": {
        "id": "02TrGj8OMfHX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAelwZcJdw4N"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_device():\n",
        "  device=\"cpu\"\n",
        "  if torch.cuda.is_available():\n",
        "    device=\"cuda\"\n",
        "  elif  torch.backends.mps.is_available():\n",
        "    device='mps'\n",
        "  else:\n",
        "    device=\"cpu\"\n",
        "  return device\n",
        "\n",
        "\n",
        "device = get_device()\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnqyNd3HtnK3",
        "outputId": "92cf3324-dd57-4422-ad56-24a25e2f2be1",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1735158641502,
          "user_tz": -540,
          "elapsed": 258,
          "user": {
            "displayName": "Jason SJ Yim",
            "userId": "00695299170620821850"
          }
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, dim_embedding, dropout=0.1, max_seq_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        postional_encoding = torch.zeros(max_seq_len, dim_embedding)\n",
        "        position = torch.arange(0, max_seq_len, dtype=torch.float).unsqueeze(1)\n",
        "        denom_term = torch.exp(torch.arange(0, dim_embedding, 2).float() * (-math.log(10000.0) / dim_embedding))\n",
        "        postional_encoding[:, 0::2] = torch.sin(position * denom_term)\n",
        "        postional_encoding[:, 1::2] = torch.cos(position * denom_term)\n",
        "        postional_encoding = postional_encoding.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('postional_encoding', postional_encoding)\n",
        "    def forward(self, x):\n",
        "        x = x + self.postional_encoding[:x.size(0), :]\n",
        "        return self.dropout(x)"
      ],
      "metadata": {
        "id": "8nIbQdvwlrfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation:\n",
        "Here's our plan for data preparation.\n",
        "Prepare the IMDb dataset for text classification:\n",
        "\n",
        "1. Load the IMDb dataset and tokenize the text using an appropriate pre-trained tokenizer.\n",
        "2.Pad and truncate the tokenized text to ensure a consistent sequence length across different examples.\n",
        "3. Ensure the data shapes are compatible with the TransformerEncoder requirements:\n",
        "  * Reshape the tokenized data (input_ids) to have a shape of (seq_length, batch_size).\n",
        "  * Reshape the attention mask to have a shape of (batch_size, seq_length).\n",
        "  * One-hot encode the labels for binary-class classification.\n",
        "\n",
        "4. Create TensorDataset to use the huggingface data on Pytorch.\n",
        "  * TensorDataset is a utility class in PyTorch (from the torch.utils.data module) that allows you to create a dataset object by wrapping one or more tensors. Each tensor in the dataset represents a different field or attribute of your data samples, such as input data, labels, or attention masks.\n",
        "5. Define custom Collate_fn\n",
        "  * The default collate function in DataLoader simply combines the samples into a batch without any additional processing. However, in many cases, you may need to perform custom processing on your samples\n",
        "  * Accorind to our shape requirement. Performe Shape transformation in this function.\n",
        "  * data: (seq_len, batch_size)\n",
        "  * atten_mask: (batch_size, seq_len)\n",
        "  * labe: one-hot-encode\n",
        "\n",
        "Important Point: Understand the Attention Mask:\n",
        "\n",
        "  * The attention mask is a binary tensor that indicates which tokens in the input sequence should be attended to by the model.\n",
        "In the attention mask tensor, the value 1 corresponds to an actual token (word or subword), while the value 0 corresponds to a padding token.\n",
        "  * The model uses this mask to ignore padding tokens during the self-attention mechanism in the Transformer architecture.\n",
        "\n",
        "Let's Code it!"
      ],
      "metadata": {
        "id": "kRGC2oBuEZXr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 런타임 30초~2분 소요\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch\n",
        "\n",
        "# 데이터셋과 토크나이저 불러오기\n",
        "dataset = load_dataset(\"imdb\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "# 데이터셋 토큰화\n",
        "def tokenize(batch):\n",
        "    return tokenizer(batch[\"text\"], padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n",
        "\n",
        "train_dataset = dataset[\"train\"].map(tokenize, batched=True, batch_size=len(dataset[\"train\"]))\n",
        "val_dataset = dataset[\"test\"].map(tokenize, batched=True, batch_size=len(dataset[\"test\"]))\n",
        "\n",
        "# 토큰화된 데이터셋에서 input_ids와 attention_mask 추출\n",
        "train_data = torch.tensor(train_dataset[\"input_ids\"])\n",
        "train_attention_mask = torch.tensor(train_dataset[\"attention_mask\"])\n",
        "train_labels = torch.tensor(train_dataset[\"label\"])\n",
        "\n",
        "val_data = torch.tensor(val_dataset[\"input_ids\"])\n",
        "val_attention_mask = torch.tensor(val_dataset[\"attention_mask\"])\n",
        "val_labels = torch.tensor(val_dataset[\"label\"])\n",
        "\n",
        "# TensorDataset 생성\n",
        "train_dataset = TensorDataset(train_data, train_attention_mask, train_labels)\n",
        "val_dataset = TensorDataset(val_data, val_attention_mask, val_labels)\n",
        "\n",
        "# DataLoader 생성\n",
        "def collate_fn(batch):\n",
        "    input_ids, attention_mask, labels = zip(*batch)\n",
        "    input_ids = torch.stack(input_ids).transpose(0, 1) # input_ids 트랜스포즈(Transpose)\n",
        "    attention_mask = torch.stack(attention_mask)       # attention_mask 트랜스포즈(Transpose)\n",
        "    labels = torch.nn.functional.one_hot(torch.tensor(labels), num_classes=2).float().to(device)\n",
        "    return input_ids, attention_mask, labels\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644,
          "referenced_widgets": [
            "e7d9a21c214d40cda6882e2f7ecab379",
            "5ff0e8ccc5a6484696dbb453a4a87d58",
            "bd33a7d4ea1d43f18e9d229535ef9170",
            "b99ec4076be740278de7305e4491a659",
            "5ed9cb53f5854a1c82ac7702e87affad",
            "6fb9502b2b7744b6a03ae42d0c122848",
            "9c2cec5db23543d4943fbe5e18fce6c7",
            "f023c6d37fc943e58fafbb7f9769192c",
            "e520d8bd9c7a4bd99561dabeef500925",
            "b7236e48b43247bf9778734a9e5923b7",
            "67cacae655794956897861948fdc4452",
            "e3c14bd255174719b662764bb8c0055e",
            "404e88a5efe241e292cc9ebe80eec6b7",
            "011a7cdb0a974a2dbb95780479d36c3d",
            "bafac1ccb53e40df9dd44824ef3e3fd1",
            "b1023ea2159a46148fc90273d44a7f5b",
            "d42484d42eff4ad9a4f788eaefcb5913",
            "ca99cbebd726440e9e3f5bca35d3ed20",
            "61c575968d0749b3b4894dd68961fd84",
            "9b1a95ebfe5b485c8dfddccd8a051406",
            "aacc612abd6e4cbd982a09d52ac4b3b6",
            "28e115987ba641fea3d1dee5ecf28909",
            "d8c93491bb6f4369a5e1cf61831b1e34",
            "ab8453a1c77c40f1ad921663f7294d42",
            "a4ba71618d2c4006a48fdbca2bf50ecf",
            "c2da9f7460de4300aa6572cf738d78f6",
            "9c75c9d2e16e44f1844b452cb58b1035",
            "a1984d76c8f34be1b4ab8faebbafa5e4",
            "8e82a034235e4a5fa3a7ff445d2a1d95",
            "c6dfd065b654486695a43fcfcfa06753",
            "7c5d046971a34923b070e9085ebf6d68",
            "73db735152714ccf8b8687046631edd5",
            "b80268a59a364f4290a4e890b023763a",
            "33b3dc48b0484cf798a3a74f8a39222c",
            "a9920e3651b1437fbf9e1688368879d3",
            "2f675cc91e764b85a19a62aa7003de56",
            "dde6638af2ff4a1196bed13f7f2db412",
            "09831c0a5272423a8917201ff97f44e0",
            "7e39de3523a24f09a1158c5dd8361619",
            "b448c76c3fd44c05941bfa8d1ed7c0fe",
            "443664804c87469a9ae17cbbc4489879",
            "cf0e757e960d400983ec0e14699e776b",
            "d1d28e2c45074b01898655898fb88823",
            "ae5fcd1d6a47463bb529938c27906125",
            "6eb87e627bd24235abdeebbd4a990dc2",
            "9cef33a71f69435d9b400333e77e26fa",
            "5d9a3434e0e04c3087a253fbc3e823b8",
            "fa33bda4c741462ea87d28c3d4d5c467",
            "823479181aea49669cb6c1398cb8bf18",
            "85fd4675c1874989a063903585b37557",
            "85fedc4816c040358dc2c73e464a76c4",
            "8833c0679191417391e34dbb1fc78842",
            "2b1b2f6578714824a1da30fad5580702",
            "208acde18ef2431984e822ddf6d75e36",
            "100b5e548a7d484bbe4f1a9c33ededd7",
            "a9271ab4139d45fc9264d428a4fdbd7b",
            "42e9397ae7a048098e1f1a1071f17951",
            "89afa732e01a4979b09efca6668e856c",
            "0c725fcff32344aba3859f55f0d2e912",
            "254a97597ae84a3ca88a3f8735e424c3",
            "3ba70a75277a48d38619c9dbaa2b8749",
            "1f12dc0842544c52ad464ea549a8ae23",
            "f8cc01f6c30d432da55a4a2cab1dd04b",
            "44a5578b7cb24d05835db4baa2491252",
            "c9f36b1f52a84e2ea5e18771c3076d53",
            "886b75643f5b42fab30cfd158afff433",
            "30ab20be3db4409baf1610b5173ad6c5",
            "3d51be7de6394211b24f8e798f60585b",
            "0c5ec40be64c46ebb76dbd2c9030eb33",
            "135278d4277c46d495c9074611968a34",
            "58a59d86c8ae47cc9c329dcc831e5f12",
            "e220dfac94bd40e1bda3006b93fb89de",
            "d8f9094aa7dd42a98f7e67ffbf150acf",
            "d26eeab04aff4115ad755a104ecf8636",
            "94bea9c505c14724b362aa97da2475e7",
            "665f59a7593b42be9310097e76397df0",
            "39d3322e8b6b40528f9f416a7ec5cf8b",
            "ce3428cd34344cb38e3c3dfb3221c209",
            "38d0bbd0286e41fc80702a5d0e7fe99e",
            "e1e4747c782746f5afa741e80029383c",
            "b85277dd94e449399ea1bdf8b8623d2a",
            "a8a7d590314d4d5798bb703078863ad0",
            "6657d3cba2924c1da96e4b718a792188",
            "d2149309738d4136b1d63f243a36fae4",
            "f8ef41c6f46045e3bcebc4d269db3fa8",
            "833f0c4118cd4771b40176a614a0b73c",
            "0827da52f737417792ee1f6c7c888ea6",
            "a7a6c862e00d4176b3c1282be3e009ee",
            "9bf9c69fedbb45bb9010c81c3dd76721",
            "cac4ddc8dfe34db3af32dc31bc6fa07d",
            "11dc13b5fca14ecb80f356a4078314cb",
            "1ecf08588a104171a3eb7a17c8d31a96",
            "1db298e267e0486189a31a9419a747e6",
            "8ad12c74dbac4ba2b345f0964bef2955",
            "7e3a3aac560d49aaac33870edfd3142d",
            "151d027e8c0046178644a6135e3be02d",
            "2e00a77734314efda2719f7a3f53f168",
            "a3d4cf152fed46c7b8f10a24da7dc5d4",
            "1b7d69438eee44c98a6d080957ad6d7d",
            "d0ed4153478d4f2e83551be0b695516c",
            "65508607a2bf4fb1812830b585eed9c0",
            "4bedb7303d2e4ca4a59fc4aba9c5ef89",
            "a91d6b39783248ecbd6aec5000957926",
            "7ebb76baff334a61a06ed73abd2f2889",
            "121e9a7c309748e9849f1126971d43e3",
            "fcda0a2aae0d4a9c846c2d14dd12e4a9",
            "5beeab1b63114addacf7ea3d599d7a65",
            "ea321814db3b4ff3a23d842e963f5bc8",
            "d6f75b7bdf3f481da13516f8afa58425",
            "a58a4ffef93c4c44bea51dec4e0d76c4",
            "34de27f1e9c44e0888ad2818e2ca2423",
            "7797d50d6ad243c9b895e31c69ac8ecc",
            "29ab6ff3311742fb855820c406a452b1",
            "4a46f620afcf41b88dcdd0bde62c566f",
            "acff75d8962f42aba99495a9204cd649",
            "57c57787c6b64ff79440ac73776c131d",
            "61c730407e334d3e9fae02f2a542e0b2",
            "feb76a4340ad4e87833a04bad2a9628d",
            "0b83f4a1d36646f4a78d95e0d8790d9b",
            "f93c343a004b4a229636b02cd6c63229",
            "984ec82c057e4b3c85c83399179fad58",
            "a5bf6c50ec1e498e93371a5a24a6ef90",
            "7454cff6154b4d9d9679fa0219ff7adb",
            "4a54fe5ad5784825bf67bdf2eb4ad21f",
            "2ff773b425e94f5baeb0cfc6541c64b2",
            "641c7900059243a58bba8d9f197c5801",
            "eabaeedd879f416d8b9c8dfff1eebb0c",
            "bb9b2809ee07432081601780584b4681",
            "49ee9d136fde4b44a094f042ce412107",
            "c5debf036b024921afc49e8b7a3c76a7",
            "91a5a6d9810d40c291fc6e37c7e75348",
            "1b7ef3421354485e9fc0a6d7683bb237",
            "250e4b3a9b7b4c18a187b6a6d4b2c9fc",
            "6db27efef13746459f3580ead5948777",
            "85dbfa47aed24acfb1395a29cd511c42",
            "06fe0ce4ae3043059b2d5571b7b2c14b",
            "44633326adc948b7a9dc2a38cdd0ae5a",
            "1a281c25d9c941aca19bb310e0014c9e",
            "9372b3fc42844d19964b220f57f34527",
            "c30e327cab2d423f8986c7815ace9032",
            "3408f518417f4f968870822443250018",
            "8f57a584d56842929660eae19c9ebcce",
            "8e788e77632d44c8a2855dbba7d6338b"
          ]
        },
        "id": "O5X0BwHAqc4-",
        "outputId": "3d20367f-4cfc-4312-a374-d6e6160ba782",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1735158770980,
          "user_tz": -540,
          "elapsed": 108900,
          "user": {
            "displayName": "Jason SJ Yim",
            "userId": "00695299170620821850"
          }
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/7.81k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e7d9a21c214d40cda6882e2f7ecab379"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/21.0M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e3c14bd255174719b662764bb8c0055e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "test-00000-of-00001.parquet:   0%|          | 0.00/20.5M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d8c93491bb6f4369a5e1cf61831b1e34"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "unsupervised-00000-of-00001.parquet:   0%|          | 0.00/42.0M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "33b3dc48b0484cf798a3a74f8a39222c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6eb87e627bd24235abdeebbd4a990dc2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a9271ab4139d45fc9264d428a4fdbd7b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "30ab20be3db4409baf1610b5173ad6c5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ce3428cd34344cb38e3c3dfb3221c209"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9bf9c69fedbb45bb9010c81c3dd76721"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d0ed4153478d4f2e83551be0b695516c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "34de27f1e9c44e0888ad2818e2ca2423"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a5bf6c50ec1e498e93371a5a24a6ef90"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "250e4b3a9b7b4c18a187b6a6d4b2c9fc"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The src_key_padding_mask in the TransformerEncoder should be a 2D boolean tensor of shape (batch_size, sequence_length). Each element in the tensor should be True if the corresponding token in the input sequence is a padding token, and False otherwise.\n",
        "\n",
        "The src_key_padding_mask is used to mask out the padding tokens in the input so that they don't contribute to the attention calculation. When the padding tokens are masked out, the transformer will not consider them while computing attention scores for the non-padding tokens."
      ],
      "metadata": {
        "id": "BD0ZNbfj3AZJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is our idea for Text Classification\n",
        "1. Initialize the following components in the constructor:\n",
        "  * Embedding layer to convert input tokens into embeddings.\n",
        "  * Positional encoding to add position information to the embeddings.\n",
        "  * Transformer encoder consisting of multiple layers, each with multi-head self-attention and feedforward neural networks.\n",
        "  * Fully connected (linear) layer for classification.\n",
        "2. Implement the init_weights method to initialize the weights of the model components.\n",
        "\n",
        "3. Implement the forward method to define the forward pass of the model.\n",
        "  * Pass the input through the embedding layer and apply positional encoding. We also add multiplication term to the embedding. The purpose of this multiplication is to scale the embeddings. This can help the model learn better and avoid vanishing gradients. The square root of the model's dimension is used as a scaling factor because it is a simple heuristic that works well in practice.\n",
        "  * Pass the embeddings through the transformer encoder with an optional key_padding_mask.\n",
        "  * Perform mean pooling on the last dimension and use the first token representation.\n",
        "    1. The output of encoder is (Seq_length, batch_size, emb_dim). Performing the mean polling across the dimesion `0` will change the data in the form of (batch_size, emb_dim)\n",
        "  * Pass the pooled representation through the fully connected layer for classification.\n",
        "  * Apply a sigmoid activation function to obtain probabilities."
      ],
      "metadata": {
        "id": "H2j5LTHgLp6S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TextClassifier(nn.Module):\n",
        "    def __init__(\n",
        "        self, vocab_size, embedding_dim, nhead, num_layers, num_classes):\n",
        "        super(TextClassifier, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.positional_encoding = PositionalEncoding(embedding_dim)\n",
        "        # 트랜스포머 인코더 층 생성\n",
        "        self.encoder_layer = nn.TransformerEncoderLayer(\n",
        "            embedding_dim, nhead)\n",
        "        self.encoder = nn.TransformerEncoder(\n",
        "            self.encoder_layer, num_layers)\n",
        "        self.fc = nn.Linear(embedding_dim, num_classes)\n",
        "        self.embedding_dim=embedding_dim\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self) -> None:\n",
        "        initrange = 0.1\n",
        "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        for layer in self.encoder.layers:\n",
        "            nn.init.xavier_uniform_(layer.self_attn.out_proj.weight)\n",
        "            nn.init.zeros_(layer.self_attn.out_proj.bias)\n",
        "            nn.init.xavier_uniform_(layer.linear1.weight)\n",
        "            nn.init.zeros_(layer.linear1.bias)\n",
        "            nn.init.xavier_uniform_(layer.linear2.weight)\n",
        "            nn.init.zeros_(layer.linear2.bias)\n",
        "        self.fc.bias.data.zero_()\n",
        "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, x, key_padding_mask=None):\n",
        "        x = self.embedding(x)* math.sqrt(self.embedding_dim)\n",
        "        x = self.positional_encoding(x)\n",
        "        x = self.encoder(x, src_key_padding_mask=key_padding_mask)\n",
        "\n",
        "        # 첫 번째 차원을 기준으로 나머지 차원(마지막 차원) 값의 평균값 생성\n",
        "        x = x.mean(dim=0)\n",
        "\n",
        "        # 분류 작업용 완전 연결 층\n",
        "        x = self.fc(x)\n",
        "        x=torch.sigmoid(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "hk5CadiUsiL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Declaring Model"
      ],
      "metadata": {
        "id": "_h9HFIpET-a3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim  # optim 모듈 임포트 추가\n",
        "import torch.nn as nn\n",
        "\n",
        "vocab_size = tokenizer.vocab_size\n",
        "embedding_dim = 512\n",
        "nhead = 8\n",
        "num_layers = 6\n",
        "num_classes = 2\n",
        "\n",
        "# 모델 생성\n",
        "model = TextClassifier(vocab_size, embedding_dim, nhead, num_layers,  num_classes).to(device)\n",
        "criterion = nn.BCELoss().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "yB7kz5AxtLQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training\n",
        "Here are a few important things to note:\n",
        "\n",
        "* batch_attention_mask = (batch_attention_mask == 0).to(device): Convert the attention mask to a boolean tensor by checking if the values are equal to 0.\n",
        "  1. The attention mask that comes from Hugging Face tokenizer is as follows:\n",
        "    * attention_mask = 1 if it is a real token\n",
        "    * attention_mask = 0 if it is a pad token\n",
        "  2. PyTorch's attention_mask requires us to send:\n",
        "    * attention_mask = False if it is a real token\n",
        "    * attention_mask = True if it is a pad token\n",
        "  3. Therefore, we are converting batch_attention_mask == 0 to True. This means we are telling the model that if it is a pad token, set attention_mask = True.\n",
        "* To avoid exploding gradients, clip the gradients of the model's parameters using torch.nn.utils.clip_grad_norm_(). This helps maintain the stability of the training process and prevents the gradients from becoming too large.\n"
      ],
      "metadata": {
        "id": "yfDDSZy1kOcL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 런타임 9분~11분 소요\n",
        "num_epochs = 1\n",
        "for epoch in range(num_epochs):\n",
        "    i=0\n",
        "    for batch_data, batch_attention_mask, batch_labels in train_dataloader:\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # attention_mask를 불리언(boolean) 텐서로 변환\n",
        "        batch_attention_mask = (batch_attention_mask==0).to(device)\n",
        "\n",
        "        outputs = model(batch_data.to(device), key_padding_mask=batch_attention_mask)\n",
        "        loss = criterion(outputs, batch_labels.to(device))\n",
        "        if i%100==0:\n",
        "          print (\"epoch \", epoch, \"batch \", i, \"loss \", loss)\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "        optimizer.step()\n",
        "        i=i+1\n",
        "\n",
        "    print(f\"Epoch: {epoch + 1}, Loss: {loss.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhkFxM_gs3uo",
        "outputId": "2454283a-2715-49c3-8c53-5d747becd858",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1735159371539,
          "user_tz": -540,
          "elapsed": 567294,
          "user": {
            "displayName": "Jason SJ Yim",
            "userId": "00695299170620821850"
          }
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch  0 batch  0 loss  tensor(0.8624, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "epoch  0 batch  100 loss  tensor(0.7319, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "epoch  0 batch  200 loss  tensor(0.7225, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "epoch  0 batch  300 loss  tensor(0.6896, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "epoch  0 batch  400 loss  tensor(0.6924, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "epoch  0 batch  500 loss  tensor(0.7088, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "epoch  0 batch  600 loss  tensor(0.7117, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "epoch  0 batch  700 loss  tensor(0.6897, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "Epoch: 1, Loss: 0.6769706010818481\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 구글 드라이브 연동\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0t_EigKOmRb",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1735159480589,
          "user_tz": -540,
          "elapsed": 36810,
          "user": {
            "displayName": "Jason SJ Yim",
            "userId": "00695299170620821850"
          }
        },
        "outputId": "d8a4cca4-a8e3-4d5f-8b85-ece365a01526"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 런타임 20초 소요\n",
        "# 독자 여러분의 구글 드라이브의 알맞은 폴더에 저장\n",
        "torch.save(model.state_dict(), \"/content/drive/MyDrive/Book6/Ch3/TextClassificationModel.pth\")"
      ],
      "metadata": {
        "id": "ijB4RY6I6WBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference\n"
      ],
      "metadata": {
        "id": "GeLxaeA4mI8o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 토크나이저 초기화\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "vocab_size = tokenizer.vocab_size\n",
        "embedding_dim = 512\n",
        "nhead = 8\n",
        "num_layers = 6 #원서 코드에서는 3으로 잘못 기재되어 고침\n",
        "num_classes = 2\n",
        "\n",
        "# 모델 생성\n",
        "model_loaded = TextClassifier(vocab_size, embedding_dim, nhead, num_layers,  num_classes).to(device)\n",
        "\n",
        "# 학습 모델 가중치(weights) 불러오기\n",
        "model_loaded.load_state_dict(torch.load('/content/drive/MyDrive/Book6/Ch3/TextClassificationModel.pth'))\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSFIm_lH_kCf",
        "outputId": "65aafd2c-2e87-4296-e90e-4a2ee78abfbf",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1735159556448,
          "user_tz": -540,
          "elapsed": 1206,
          "user": {
            "displayName": "Jason SJ Yim",
            "userId": "00695299170620821850"
          }
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TextClassifier(\n",
              "  (embedding): Embedding(30522, 512)\n",
              "  (positional_encoding): PositionalEncoding(\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder_layer): TransformerEncoderLayer(\n",
              "    (self_attn): MultiheadAttention(\n",
              "      (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "    )\n",
              "    (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "    (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "    (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "    (dropout1): Dropout(p=0.1, inplace=False)\n",
              "    (dropout2): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): TransformerEncoder(\n",
              "    (layers): ModuleList(\n",
              "      (0-5): 6 x TransformerEncoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Printing total parameter of our model"
      ],
      "metadata": {
        "id": "FZQSr0QImPDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(\"Total trainable parameters:\", total_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8ZAWHdjOn9r",
        "outputId": "ab50d6ed-0a5d-49a3-fa55-dd018d07a116",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1735159629556,
          "user_tz": -540,
          "elapsed": 395,
          "user": {
            "displayName": "Jason SJ Yim",
            "userId": "00695299170620821850"
          }
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total trainable parameters: 37694978\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 주어진 텍스트에서 추론을 실행하는 함수\n",
        "def infer(text):\n",
        "    # 입력 텍스트 토큰화\n",
        "    tokens = tokenizer.encode_plus(text, padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n",
        "    input_ids = tokens[\"input_ids\"].to(device).transpose(0,1)\n",
        "\n",
        "    attention_mask = tokens[\"attention_mask\"]\n",
        "    attention_mask=(attention_mask==0).to(device)\n",
        "    print(input_ids.shape)\n",
        "    print(attention_mask)\n",
        "\n",
        "    # 추론 실행\n",
        "    with torch.no_grad():\n",
        "        output = model(input_ids, key_padding_mask=attention_mask)\n",
        "    # 출력을 클래스 확률로 변환\n",
        "    probabilities = output.squeeze(0)\n",
        "    return probabilities\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CrNKSUlp6bmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 샘플 텍스트로 테스트\n",
        "example_text = \"This movie is  good! .\"\n",
        "probabilities = infer(example_text)\n",
        "\n",
        "print(\"Probabilities:\", probabilities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gavMpQn9B9A",
        "outputId": "9ee6359d-ef6f-40b2-b347-1b5616f79715",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1735159637558,
          "user_tz": -540,
          "elapsed": 303,
          "user": {
            "displayName": "Jason SJ Yim",
            "userId": "00695299170620821850"
          }
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 1])\n",
            "tensor([[False, False, False, False, False, False, False, False]],\n",
            "       device='cuda:0')\n",
            "Probabilities: tensor([0.5042, 0.5029], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary:\n",
        "The provided code offers a basic implementation of a TransformerEncoder for text classification. The primary goal is to demonstrate how to utilize a TransformerEncoder for this task. In subsequent chapters, we will explore optimized versions of Transformer-based classification. To achieve better results with the current code, consider increasing the number of encoder layers and fine-tuning various parameters."
      ],
      "metadata": {
        "id": "MdF9gaqdMSEY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Generation\n",
        "## Decoder-Only Layer\n",
        "1. We will use the Shakespeare dataset to create a decoder-only model that generates text in the style of Shakespeare."
      ],
      "metadata": {
        "id": "T2F5wPqSPH-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n"
      ],
      "metadata": {
        "id": "fnop0O8VB-ia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What we are doing Here?\n",
        "1. This code defines a custom PyTorch dataset called ShakespeareDataset.\n",
        "2. It takes a file path to a text file and a tokenizer as input. The dataset reads the file and splits it into examples of size block_size.\n",
        "3. Each example is then tokenized using the tokenizer and padded or truncated to a maximum length of block_size. The resulting tokenized examples are stored in a list."
      ],
      "metadata": {
        "id": "Q-0Oowr8K9hT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ShakespeareDataset(Dataset):\n",
        "    def __init__(self, file_path, tokenizer, block_size=128):\n",
        "        self.block_size = block_size\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "        with open(file_path, 'r') as f:\n",
        "            self.data = f.read()\n",
        "\n",
        "        self.examples = []\n",
        "        for i in range(0, len(self.data)-self.block_size, self.block_size):\n",
        "            example = self.data[i:i+self.block_size]\n",
        "            tokenized = self.tokenizer(example, padding='max_length', truncation=True, max_length=block_size, return_tensors='pt')\n",
        "            self.examples.append(tokenized)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.examples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_ids = self.examples[idx]['input_ids'].squeeze()\n",
        "        attention_mask = self.examples[idx]['attention_mask'].squeeze()\n",
        "        return input_ids, attention_mask\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hmi7tWV5CHG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os,urllib\n",
        "url = 'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'\n",
        "# 독자 여러분의 알맞은 구글 드라이브 폴더로 대치\n",
        "filename = '/content/drive/MyDrive/Book6/Ch3/input.txt'\n",
        "if not os.path.isfile(filename):\n",
        "    urllib.request.urlretrieve(url, filename)\n"
      ],
      "metadata": {
        "id": "ydFhPczFCNAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = ShakespeareDataset(filename, tokenizer)"
      ],
      "metadata": {
        "id": "7IGiDxcFC6ev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What we are doing here?\n",
        "1. `inputs = torch.stack(inputs).transpose(0, 1)`: The dimension of input needed is (seq_length, batch_size). Thus, we are transposing.\n",
        "2. `torch.stack(inputs)` takes a list of tensors and stacks them along a new dimension (the result has one more dimension than the input tensors).\n",
        "  * For example, each inputs has dimension of (128). If the batch size 6; then, stacking operation will produce list of (6,128)=> (batch_size, seq_length)\n",
        "  * transpose will result in (128,6)==> (seq_length, batch_size)"
      ],
      "metadata": {
        "id": "7Thc88UNLYZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "def collate_fn(batch):\n",
        "    inputs, masks = zip(*batch)\n",
        "    inputs = torch.stack(inputs).transpose(0, 1)\n",
        "    masks = torch.stack(masks)\n",
        "    return inputs, masks\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=4, collate_fn=collate_fn,shuffle=True)\n"
      ],
      "metadata": {
        "id": "Fz0fsqDeDx48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터의 차원 확인\n",
        "item=next(iter(train_dataloader))\n",
        "input_ids,attention_masks=item\n",
        "print(input_ids.shape, attention_masks.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmZMRIs-F-Ri",
        "outputId": "8fbbd4ba-609e-443a-d5e6-d20e44ca4502",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1735159668482,
          "user_tz": -540,
          "elapsed": 328,
          "user": {
            "displayName": "Jason SJ Yim",
            "userId": "00695299170620821850"
          }
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 4]) torch.Size([4, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's Declare Positional Encoding Class.\n",
        "1. It is same as what we discussed in earlier example"
      ],
      "metadata": {
        "id": "oXL3V8RXM3Dm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, dim_embedding, dropout=0.1, max_seq_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        postional_encoding = torch.zeros(max_seq_len, dim_embedding)\n",
        "        position = torch.arange(0, max_seq_len, dtype=torch.float).unsqueeze(1)\n",
        "        denom_term = torch.exp(torch.arange(0, dim_embedding, 2).float() * (-math.log(10000.0) / dim_embedding))\n",
        "        postional_encoding[:, 0::2] = torch.sin(position * denom_term)\n",
        "        postional_encoding[:, 1::2] = torch.cos(position * denom_term)\n",
        "        postional_encoding = postional_encoding.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('postional_encoding', postional_encoding)\n",
        "    def forward(self, x):\n",
        "        x = x + self.postional_encoding[:x.size(0), :]\n",
        "        return self.dropout(x)"
      ],
      "metadata": {
        "id": "m99atpU2KFw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's Declare Model\n",
        "### Model Architecture\n",
        "1. This model is a Transformer-based decoder-only language model, which takes as input a target sequence (tgt) and an  memory sequence (memory) and generates an output sequence of the same length as the input sequence.\n",
        "\n",
        "2. The input target sequence is first passed through an embedding layer and a positional encoding layer. Similarly, the input memory sequence is passed through an embedding layer and a positional encoding layer.\n",
        "\n",
        "3. During, Training\n",
        "  * `memory` is train data of shape (seq_len, batch_size)\n",
        "  * `target`:During model training, the target sequence would be the input sequence shifted by one position.\n",
        "\n",
        "4. These processed input sequences are then fed into the Transformer decoder, which consists of multiple Transformer decoder layers. Each decoder layer processes the input sequences using multi-head self-attention and a feedforward neural network.\n",
        "\n",
        "5. Finally, the output of the Transformer decoder is passed through a linear layer (fully-connected neural network) to generate the final output sequence, with each element of the sequence representing the probability distribution over the vocabulary of the target language."
      ],
      "metadata": {
        "id": "ujk42ZNKNaMA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDecoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, num_layers, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        self.memory_embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.memory_pos_encoder = PositionalEncoding(embedding_dim, dropout)\n",
        "        self.tgt_embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.tgt_pos_encoder = PositionalEncoding(embedding_dim, dropout)\n",
        "        self.decoder = nn.TransformerDecoder(\n",
        "            nn.TransformerDecoderLayer(d_model=embedding_dim, nhead=8,\n",
        "                                       dim_feedforward=2048,\n",
        "                                       dropout=dropout),\n",
        "            num_layers=num_layers)\n",
        "\n",
        "        self.fc = nn.Linear(embedding_dim, vocab_size)\n",
        "        self.d_model=embedding_dim\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self) -> None:\n",
        "        initrange = 0.1\n",
        "\n",
        "        # 임베딩 층 초기화\n",
        "        nn.init.uniform_(self.memory_embedding.weight, -initrange, initrange)\n",
        "        nn.init.uniform_(self.tgt_embedding.weight, -initrange, initrange)\n",
        "\n",
        "        # 디코딩 층 초기화\n",
        "        for param in self.decoder.parameters():\n",
        "            if param.dim() > 1:\n",
        "                nn.init.xavier_uniform_(param)\n",
        "\n",
        "        # 출력 층 초기화\n",
        "        nn.init.uniform_(self.fc.weight, -initrange, initrange)\n",
        "        nn.init.zeros_(self.fc.bias)\n",
        "\n",
        "    def forward(self, tgt,  memory=None, tgt_mask=None, memory_mask=None, memory_key_padding_mask=None,tgt_key_padding_mask=None):\n",
        "        tgt = self.tgt_embedding(tgt) * self.d_model ** 0.5\n",
        "        tgt=self.tgt_pos_encoder(tgt)\n",
        "        print(tgt)\n",
        "        memory=self.memory_embedding(memory) * self.d_model ** 0.5\n",
        "        memory=self.memory_pos_encoder(memory)\n",
        "        print(memory)\n",
        "        output = self.decoder(\n",
        "            tgt=tgt, memory=memory, tgt_mask=tgt_mask,\n",
        "            memory_mask=memory_mask,\n",
        "            memory_key_padding_mask=memory_key_padding_mask,\n",
        "            tgt_key_padding_mask=tgt_key_padding_mask\n",
        "            )\n",
        "        print(output)\n",
        "        output = self.fc(output)\n",
        "        return output"
      ],
      "metadata": {
        "id": "kxVdZrgWD4bc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eS4oE3_RlkcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 번역서 03.4 부분의 4. memory_key_padding_mask 내용은 아래 코드에서 4 부분을 참조하세요."
      ],
      "metadata": {
        "id": "gkBajgNK0-Kp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parameters  for decoding Layer\n",
        "\n",
        "1. tgt: The input sequence to the decoder layer. It is a tensor of shape (seq_len, batch_size, emb_dim) where seq_len is the length of the input sequence and batch_size is the number of sequences in a batch.\n",
        "\n",
        "2. memory: The output of the last layer of the encoder. It is a tensor of shape (src_seq_len, batch_size, emb_dim) where src_seq_len is the length of the input sequence in the encoder.\n",
        "\n",
        "3. tgt_mask: An optional tensor of shape (seq_len, seq_len) representing the mask for the input sequence. It is used to prevent the decoder from attending to future tokens.\n",
        "The format should be:\n",
        "\n",
        "```\n",
        "tensor([[0., -inf, -inf],\n",
        "        [0., 0., -inf],\n",
        "        [0., 0., 0.]], device='mps:0')\n",
        "```\n",
        "  * in above example, seq_length=3\n",
        "  * where `-inf` signifies the tokens that need to be masked\n",
        "\n",
        "4. memory_mask: 인코더 출력 시퀀스에 사용되는 마스크를 표기하는 (seq_len, src_seq_len) 형태의 옵션형 텐서입니다. 이는 디코더가 인코더 입력 시퀀스에 있는 미래 토큰들에 어텐션을 취하지 못하게 방지합니다.\n",
        "(An optional tensor of shape (seq_len, src_seq_len) representing the mask for the encoder output sequence. It is used to prevent the decoder from attending future tokens in the encoder input sequence.)\n",
        "\n",
        "```\n",
        "tensor([[0., -inf, -inf],\n",
        "        [0., 0., -inf],\n",
        "        [0., 0., 0.]], device='mps:0')\n",
        "```\n",
        "  * 위의 예에서 seq_length=3 입니다.(in above example, seq_length=3)\n",
        "  * `-inf`는 마스크가 필요한 토큰의 위치를 의미합니다. (where `-inf` signifies the tokens that need to be masked)\n",
        "\n",
        "```\n",
        "통상적으로, 여러분은 메모리를 마스크하지 않는 경우 다음과 같은 텐서를 사용합니다.\n",
        "(Usually, you will not mask the memory: Thus, you will pass:)\n",
        "tensor([[0., 0, 0],\n",
        "        [0., 0., 0],\n",
        "        [0., 0., 0.]], device='mps:0')\n",
        "\n",
        "5. tgt_key_padding_mask: An optional tensor of shape (batch_size, seq_len) representing the mask for padding tokens in the input sequence.\n",
        "\n",
        "```\n",
        "tensor([[False, False, False],\n",
        "        [False, False, False],\n",
        "        [False, True, False],\n",
        "        [True, True, False]], device='mps:0')\n",
        "```\n",
        "  * In above example, batch_size=4,  seq_len=3\n",
        "  * True signifies the particular token is padded token and mask it\n",
        "  * False signifies the particular token is padded token and mask it\n",
        "\n",
        "6. memory_key_padding_mask: An optional tensor of shape (batch_size, src_seq_len) representing the mask for padding tokens in the encoder output sequence.\n",
        "\n",
        "```\n",
        "tensor([[False, False, False],\n",
        "        [False, False, False],\n",
        "        [False, True, False],\n",
        "        [True, True, False]], device='mps:0')\n",
        "```\n",
        "  * In above example, batch_size=4,  seq_len=3\n",
        "  * True signifies the particular token is padded token and mask it\n",
        "  * False signifies the particular token is padded token and mask it\n"
      ],
      "metadata": {
        "id": "IIAcfLAYdUjV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_square_subsequent_mask(sz):\n",
        "    mask = (torch.triu(torch.ones((sz, sz), device=device)) == 1).transpose(0, 1)\n",
        "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "    return mask.to(device)\n",
        "\n",
        "\n",
        "def create_mask(src, tgt,tokenizer_src=tokenizer,tokenizer_tgt=tokenizer):\n",
        "    src_seq_len = src.shape[0]\n",
        "    tgt_seq_len = tgt.shape[0]\n",
        "\n",
        "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
        "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=device).type(torch.bool)\n",
        "\n",
        "    src_padding_mask = (src == tokenizer_src.pad_token_id).transpose(0, 1)\n",
        "    tgt_padding_mask = (tgt == tokenizer_tgt.pad_token_id).transpose(0, 1)\n",
        "    return src_mask.to(device), tgt_mask.to(device), src_padding_mask.to(device), tgt_padding_mask.to(device)"
      ],
      "metadata": {
        "id": "xILYGE1JHYt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "#device='mps' # 코랩 사용시 불필요한 코드라서 주석 처리함\n",
        "model = TransformerDecoder(vocab_size=tokenizer.vocab_size, embedding_dim=768, num_layers=3, dropout=0.1)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n"
      ],
      "metadata": {
        "id": "wtUNadG0D_xb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise\n",
        "1. Write the Training Loop\n",
        "2. Write the Inference Loop"
      ],
      "metadata": {
        "id": "2wMH1JTiB87y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer Layer\n",
        "## Machine Translation\n",
        "1. Machine Translation is the task of converting a text from one language to another. In this context, we will focus on English to German (en-de) translation. The task involves processing a sequence of tokens in one language and producing a corresponding sequence of tokens in another language.\n",
        "2. We will use Encoder-Decoder Layer of Transformer\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "S0LeOzAKGm9S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's Download the Data"
      ],
      "metadata": {
        "id": "SUiQQ3nCtDf2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import AutoTokenizer\n",
        "from datasets import load_dataset\n",
        "\n",
        "# 데이터셋과 토크나이저 불러오기\n",
        "dataset = load_dataset(\"iwslt2017\", \"iwslt2017-de-en\", split=\"train[:1%]\")  # Only use a 1% portion of the dataset\n",
        "tokenizer_src = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "tokenizer_tgt = AutoTokenizer.from_pretrained(\"bert-base-german-cased\")\n",
        "\n",
        "# 'Do you wish to run the custom code?'라는 질문이 결과 창에 나오면 소문자 y를 입력하고 엔터키를 누르면 됩니다.\n"
      ],
      "metadata": {
        "id": "M3_12mzqKME1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 584,
          "referenced_widgets": [
            "ba1352a1f0a7440fbb60a42de96cfd15",
            "99ce230c29ad48e9b2543dea41789193",
            "0734f45bb72a4c8b8d7fe1d9066a26f5",
            "4a90a984946e4a0c9f52aa151781f640",
            "17649864c032468e9ca4d423373800e4",
            "f10dc2dc398f485981338a26f7029207",
            "5b52b4c2245741bcad84de7e156bf698",
            "6298021c96dd4e8891f89f0186d33a5b",
            "093997e6c41647e485c8c019118abd01",
            "38428556477746a893a834154772d806",
            "cf247b91f737485f82dfb1f7ed7515ac",
            "e175624100c34f0d972b0a871713ee08",
            "886b1efea3924661978970c6d4352bde",
            "e5df05bfc5b2474a97302202de822403",
            "ea83dd8253c0409c9066f35506119686",
            "99bb7c6b3b59409886163c66c65cdb79",
            "2dae9bd9be514f6daa581dfd1323c62f",
            "3bbe0ffadbdf4521adcba135eea6d9a1",
            "19cdcd2ffc884d05bdd8e772ec3ac420",
            "6f5dde29dcf143d6a5cb364203bbc423",
            "dae3de8841fd45878383819091228038",
            "67856ad0436944a2971d4b391a41b560",
            "7a17fbc773da4d38b30dca1655e6ce9f",
            "91a71bc753e142f6a9985fd680085f39",
            "c4278e76054c4487b86052ca82cfab87",
            "35c2b5933e1348b4b0a48bb76bab0588",
            "cd61b99ff0e444cb8e134ddb5634c252",
            "b77fd483000d4a1b966bf3a8a177291d",
            "a84ee21d88f34d5db4dd76e4363b7ef4",
            "401f40a1c9574203ae7242b47dab0ee2",
            "d5307aba9e58482ba454b8bfd5f551d8",
            "82a22d0175ca469c9b93c9a37c16130d",
            "cec18300d6be470ab0d0577ef56b8493",
            "e6ec1973c5234a8d93ffc0ba8fac8c18",
            "40371f1ca5a04f2f83423d221cd79532",
            "ed9f7504b30a48a08910a84695e6e215",
            "60102bc1a2f942189a2941573b5526d2",
            "e0e5771beafb4eabb8919c252607c63c",
            "e0c4d65395714431839aebbdfad32ddb",
            "ec7a7dc97c12466586749aea2b625a9f",
            "f67bffe904f0435db0ab640934fcf9e4",
            "62f1e0ea015b4b748d1ea0bc7ee4a8e0",
            "0c6bec6b59894a708b9519ed9bb83bbb",
            "fb57489d331d4b8aa1ca5bc0e7758fe7",
            "8a98474cc84041fb83fc692d38b6a621",
            "b5126a364abb48cf888d68936e92b413",
            "5f238180d4b5456d809b108948deb1e1",
            "0813d94b70a646d3a668d76a5d2871c4",
            "e944277fd94f433a9793083b5bf9fe1a",
            "3b6de81e52a44b749e620120c5f58323",
            "a72d698c6d0f46a7819acfbb0cc6befc",
            "0b76f81d9e194f0e8bb93df911f79353",
            "1b7e13ff50364f7095368925ae39ca8f",
            "b2fee1c6ba794045a14586feca1f3faa",
            "a8d4d45d34c6477e9057111e1ec29fde",
            "bbfcc2da813049ec9715be814175ccf0",
            "c13ce46d937d41fc96c2281a2dbd874f",
            "065a00ca9f3f406981d12b92a35bda62",
            "1e8553f117734eff9c56e9597d46c6a4",
            "6f52af2ed35740a79c1beacbd0a646a1",
            "0458c1689a2b4a7db9d79fdfa4d42852",
            "cc9ac8cb57c84f17b5020bfc903d6378",
            "4b7d21f1573842218856da0f6f05a948",
            "63d2c96aec77439ead2acc75612ff87c",
            "e8f8a9adcc15440ca89894b5c44a0a58",
            "7aba06334c5a49708f16a4877f3b2b14",
            "6cb63a58d3ec4cb2ac8139d65afd55c1",
            "f63ec4214bea4ca5bba96f5eac400aa7",
            "40a93c30244840a590def5cbf21fccc0",
            "0d3886b1565d4a27bffef14f53788d7a",
            "349a8d2b247749eeb9d66a87923d2238",
            "54db0d65400b402aa0b9cb0ec79726a1",
            "42509244acd1447689a6d0fd880ec07b",
            "df49e298cdfa475185b1784561f44089",
            "e9d5f4d147504738bf66db46abfa27ec",
            "707065fca47a4a3ba439003d8335e81b",
            "9e2dbe67d19d4a6aa4142e75e7f9d177",
            "99a48eaa80b242a1a15a2eaebd2d8f14",
            "6e4ccb5750de486db911b48ea27cbaa5",
            "0abb405c1bca4a1bbb679b630d3bd329",
            "a46df94ebcd34c78993e4b4e4a7c1d0e",
            "af439c92c7a24542b23f7293b1288105",
            "7faf5d9bdf954c63be940da4e465a9ea",
            "889499bda57e49a098502e97a41a144f",
            "219ab90ced074ce4a5fd799da6311472",
            "b1b2eb49fab149399a56e7ad85675d44",
            "1958dd4baf9548b8b36ecfe61a49d942",
            "71ca17f7b3be40f39c2244780b606a3b",
            "58caafa125a04594bb74a0aaebf5d152",
            "4287a55f6cfb488c82c031242f4d8025",
            "16cd2f235ba14a9ca43656581633bdec",
            "624901985ac14491ab1532d165ecabb3",
            "ccb57441c8db44f8987ca0d4575ce38b",
            "8ff628c99dbd4d06b164687981712eb2",
            "ea51e2246eb540f6934859d16c0cb065",
            "12016f083b1745dfa746b9dab88f3857",
            "1787988063d24b77b973edd50e244bb4",
            "4abcb9ffc0604c34b58a2b326cb98899",
            "5287259adaf24d0e8aba026cec48596c",
            "b24b83b082bc425f9cc89a6e449df0bd",
            "5efd72d86a874462ae3ecde99008fe9d",
            "122f682484dc4e6a834be8c5c79d2a34",
            "62586ce213c74f3ab0b014eec127c32c",
            "e8e398bd84984a6b82249fd798015d71",
            "007188a17d1e49ad93f5c81df29aa19c",
            "7e2a6d55a7b740c89e3c83882bdcf884",
            "64f02afbf4444577ba8ac0b934dbe087",
            "2d1a1ef073074e5a8b981c6a91e51daa",
            "b26533c2ba0f4822b7f2510f96cf3eaf",
            "dc69d9c3189643d6abe4df9a212bc622",
            "919aca8a59ec4e54b1e86494a991ed52",
            "85b04f2cc5b64e24909df87c64daeba7",
            "aeac2e8ab15c4ad381c9a29054eb12e5",
            "2da0da4234e748e28cf0daa94a72036d",
            "e296878cec2f4914802d2e5ac45fd7c3",
            "1c061d1d6c79423a8bd96670044a6d58",
            "d90b0ace331a42f3b8f1453f94c2c63e",
            "ba3620cda599479d949e53c779fb8f75",
            "1075fcf9ae824d6db21bec77fc32300e",
            "5fcc2a00ece9463e986389cb6a1fdf8e",
            "86e19399d67d4ea0919aa644d56c9071",
            "eb1c319c46bd43cbba277703af3a8cfa",
            "9ed754f06648494cab180714596ea688",
            "460721de40294ae5bab6c7a1924e3556",
            "3a654792bd914d26bcdb25762b1c0c87",
            "eb03e0ae3968477d9ad1895c45c68509",
            "f4baffbcb5694e2987e7611d60bc1009",
            "cac25d8e80dd4b30a03a84802ecf90e7",
            "2092bb098256447092d7010d50d8f4aa",
            "9e170ca2aa7e426b917db954bfc67f09",
            "14fb5749414d44908de51da8f75b1a21",
            "21bff9cdf6d74caeabe3b83004aab758",
            "c8b1c6b814d74ab487123668c34df56b",
            "0fd825953e7d42dd89b3ab5033afb411",
            "008852ac5cfd46868f9fb54bc808bd89",
            "50933a4608f54f4b90c2bbae30f37ba9",
            "51aec1455c514942a1833c0e07736d5c",
            "4291b34514d443b4b9d4267ec8c5dc9c",
            "b611730db3ec4381a6d06dcf52b4bde1",
            "b987dd2fba1a4406922fc90dec107b8e",
            "2d651408c14b43328b5a8379f34cd326",
            "246ef5b9c6a149caa7ca0d3fb5d6fdec",
            "bb928cc1cb614e86817b761daad651b9",
            "86fc7fb81ee54eb9951500014a0ddd45",
            "0a544b10f56d436e97880999ff52e796",
            "d65479aa454b4132949eee7e8f80ad39",
            "7b1fc1babfaa4f439f1e268a91fa35ac",
            "61fdb34a2fb54fd8b4dd9e12d8181c04",
            "c9d312406d5444529ad4756dca5402a6",
            "89b462e78ff2420ba73c8f14f51409fe",
            "0e64fb31619e4ad7b86989117ac842d8",
            "42f76d58c1ac425ba02df15b0810aae7",
            "9411449d2fe84df3868564000a1827c6",
            "ee531651e07e4c038f30f98463655e58"
          ]
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1735159731940,
          "user_tz": -540,
          "elapsed": 26390,
          "user": {
            "displayName": "Jason SJ Yim",
            "userId": "00695299170620821850"
          }
        },
        "outputId": "5ff0a99b-b9cd-442e-c5e5-7726ac819ff7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/18.5k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ba1352a1f0a7440fbb60a42de96cfd15"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "iwslt2017.py:   0%|          | 0.00/8.17k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e175624100c34f0d972b0a871713ee08"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The repository for iwslt2017 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/iwslt2017.\n",
            "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
            "\n",
            "Do you wish to run the custom code? [y/N] y\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "de-en.zip:   0%|          | 0.00/16.8M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7a17fbc773da4d38b30dca1655e6ce9f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/206112 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e6ec1973c5234a8d93ffc0ba8fac8c18"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/8079 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8a98474cc84041fb83fc692d38b6a621"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/888 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bbfcc2da813049ec9715be814175ccf0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6cb63a58d3ec4cb2ac8139d65afd55c1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "99a48eaa80b242a1a15a2eaebd2d8f14"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "58caafa125a04594bb74a0aaebf5d152"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b24b83b082bc425f9cc89a6e449df0bd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "919aca8a59ec4e54b1e86494a991ed52"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/433 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eb1c319c46bd43cbba277703af3a8cfa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/255k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c8b1c6b814d74ab487123668c34df56b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/485k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "86fc7fb81ee54eb9951500014a0ddd45"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1SVoXMDxQh2",
        "outputId": "8705abf8-9dbf-4934-9aad-07fd9e7a6c04",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1735159739700,
          "user_tz": -540,
          "elapsed": 269,
          "user": {
            "displayName": "Jason SJ Yim",
            "userId": "00695299170620821850"
          }
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'translation': {'de': 'Vielen Dank, Chris.',\n",
              "  'en': 'Thank you so much, Chris.'}}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom Dataset to Prepare Data\n",
        "1. Let's Prepare the data so that we have src_tokem and tgt_token of same length\n",
        "2. Here, we define the max length of token is 50"
      ],
      "metadata": {
        "id": "PQLQhdOixJjX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, dataset, tokenizer_src, tokenizer_tgt, max_length=50):\n",
        "        self.dataset = dataset\n",
        "        self.tokenizer_src = tokenizer_src\n",
        "        self.tokenizer_tgt = tokenizer_tgt\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        src_text = self.dataset[idx]['translation']['en']\n",
        "        tgt_text = self.dataset[idx]['translation']['de']\n",
        "\n",
        "        src_tokens = self.tokenizer_src.encode_plus(\n",
        "            src_text,\n",
        "            max_length=self.max_length,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        tgt_tokens = self.tokenizer_tgt.encode_plus(\n",
        "            tgt_text,\n",
        "            max_length=self.max_length,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        return src_tokens[\"input_ids\"].squeeze(),tgt_tokens[\"input_ids\"].squeeze()\n"
      ],
      "metadata": {
        "id": "nFHDcmuR1bb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = TranslationDataset(dataset, tokenizer_src, tokenizer_tgt)\n"
      ],
      "metadata": {
        "id": "sJUXR6Bmx05O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.tensor 생성 후 샘플 데이터 확인\n",
        "train_data[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZng6T8A1Sox",
        "outputId": "dda0c540-95fb-478b-d050-5447b531bd3a",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1735159749196,
          "user_tz": -540,
          "elapsed": 275,
          "user": {
            "displayName": "Jason SJ Yim",
            "userId": "00695299170620821850"
          }
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([  101,  1045,  2031,  2042, 10676,  2185,  2011,  2023,  3034,  1010,\n",
              "          1998,  1045,  2215,  2000,  4067,  2035,  1997,  2017,  2005,  1996,\n",
              "          2116,  3835,  7928,  2055,  2054,  1045,  2018,  2000,  2360,  1996,\n",
              "          2060,  2305,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]),\n",
              " tensor([    3,  1671,  4058,  4899, 15227,    88,   534, 13854, 26918,    42,\n",
              "          1169,  9334, 26897,  9830,  2122,   142,    30,  2709,  2055,  2636,\n",
              "             7, 18930,    81, 10183,  4468,  2085,  6738,  4253, 26914,     4,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]))"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analysis: If you look at the above sample, `0` represents the padding token"
      ],
      "metadata": {
        "id": "y79RLQjqxwKs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create DataLoader:\n",
        "* The output after the dataloder should be of shape (seq_len, batch_size)\n",
        "* Thus, we have transposed both src_ids, and tgt_ids"
      ],
      "metadata": {
        "id": "m7wRvFs1yXiL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    src_ids ,tgt_ids = zip(*batch)\n",
        "    src_ids = torch.stack(src_ids).transpose(0, 1)\n",
        "    tgt_ids = torch.stack(tgt_ids).transpose(0, 1)\n",
        "    return src_ids, tgt_ids\n",
        "dataloader = DataLoader(train_data, batch_size=16, shuffle=True, collate_fn=collate_fn)\n"
      ],
      "metadata": {
        "id": "zlV3mT6o5A8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "item=next(iter(dataloader))\n",
        "src_ids,tgt_ids=item\n",
        "print('src_ids ',src_ids.shape)\n",
        "print(' tgt_ids ',tgt_ids.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNWSlh-y66nP",
        "outputId": "bcf35603-59a4-4057-c8e3-79e859923a72",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1735159755976,
          "user_tz": -540,
          "elapsed": 395,
          "user": {
            "displayName": "Jason SJ Yim",
            "userId": "00695299170620821850"
          }
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_ids  torch.Size([50, 16])\n",
            " tgt_ids  torch.Size([50, 16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It looks perfect:\n",
        "1. the shape of source and target are [seq_length, batch_size]\n"
      ],
      "metadata": {
        "id": "QEn5D1vS86YY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchtext\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, dim_embedding, dropout=0.1, max_seq_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        postional_encoding = torch.zeros(max_seq_len, dim_embedding)\n",
        "        position = torch.arange(0, max_seq_len, dtype=torch.float).unsqueeze(1)\n",
        "        denom_term = torch.exp(torch.arange(0, dim_embedding, 2).float() * (-math.log(10000.0) / dim_embedding))\n",
        "        postional_encoding[:, 0::2] = torch.sin(position * denom_term)\n",
        "        postional_encoding[:, 1::2] = torch.cos(position * denom_term)\n",
        "        postional_encoding = postional_encoding.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('postional_encoding', postional_encoding)\n",
        "    def forward(self, x):\n",
        "        x = x + self.postional_encoding[:x.size(0), :]\n",
        "        return self.dropout(x)"
      ],
      "metadata": {
        "id": "R3Bm4meI2DqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer Model\n",
        "What we are doing?\n",
        "1. `forward`\n",
        "  * The source and target sequences are embedded and scaled by the square root of the embedding dimension.\n",
        "  * The positional encodings are added to the embeddings.\n",
        "  * The Transformer processes the source and target sequences, with masking\n",
        "    1. src_mask, trg_mask==> This is done to prevent future flow of information\n",
        "    2. src_padding_mask, trg_padding_mask ==> This is done to mask padded data. We are doing this so that model donot attent to padded tokens\n",
        "  * The output of the Transformer is passed through a fully connected layer to get the predicted target sequence..\n",
        "  * The model is predicting next token in german given all the tokens in en, and tokens untill the current step in german.\n",
        "  "
      ],
      "metadata": {
        "id": "q-VTmjS5ycak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self,num_encoder_layers, num_decoder_layers, d_model,\n",
        "                 nhead, src_vocab_size=tokenizer_src.vocab_size,\n",
        "                 tgt_vocab_size=tokenizer_tgt.vocab_size,\n",
        "                 dim_feedforward=512, dropout=0.1):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        self.src_embedding = nn.Embedding(input_dim, d_model)\n",
        "        self.trg_embedding = nn.Embedding(output_dim, d_model)\n",
        "        self.src_pos_encoder = PositionalEncoding(d_model, dropout)\n",
        "        self.trg_pos_encoder = PositionalEncoding(d_model, dropout)\n",
        "        self.transformer = nn.Transformer(\n",
        "            d_model=d_model, nhead=nhead,\n",
        "            num_encoder_layers=num_encoder_layers,\n",
        "            num_decoder_layers=num_decoder_layers,\n",
        "            dim_feedforward=dim_feedforward, dropout=dropout)\n",
        "        self.fc = nn.Linear(d_model, tgt_vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.d_model = d_model\n",
        "\n",
        "    def forward(self, src, trg, src_mask=None,\n",
        "                src_padding_mask=None, trg_mask=None,\n",
        "                trg_padding_mask=None, memory_key_padding_mask=None):\n",
        "\n",
        "        src = self.src_embedding(src) * (self.d_model ** 0.5)\n",
        "        src = self.src_pos_encoder(src)\n",
        "        trg = self.trg_embedding(trg) * (self.d_model ** 0.5)\n",
        "        trg = self.trg_pos_encoder(trg)\n",
        "        output = self.transformer(src, trg,src_mask, trg_mask, None,\n",
        "                                  src_padding_mask, trg_padding_mask,\n",
        "                                  memory_key_padding_mask)\n",
        "        output = self.fc(self.dropout(output))\n",
        "        return output"
      ],
      "metadata": {
        "id": "F2_Yt_Nv1sSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's Creating Masking\n",
        "1. `generate_square_subsequent_mask` will create following matrix for the tgt_msk. Here, we supposed the tgt sequence length is 3.\n",
        "\n",
        "```\n",
        "tensor([[ 0., -inf, -inf],\n",
        "        [ 0.,  0., -inf],\n",
        "        [ 0.,  0.,  0.]])\n",
        "```\n",
        "\n",
        "\n",
        "2. This means that each token would only be allowed to attend to the tokens that have already been generated during decoding.\n",
        "3. `src_mask` square matrix fill with False. This means, we are not masking any source sequence\n",
        "4. `src_padding_mask` and `tgt_padding_mask`: It looks at the src and tgt which is filled with padded token. And, mask all padded tokens\n",
        "5. We transpose `src_padding_mask` and `tgt_padding_mask` because Transformer requires the dimension to be [batch_size, seq_len]. This is opposite to the Transformer requirement for src and tgt to be [seq_length, batch_size]\n"
      ],
      "metadata": {
        "id": "Onvy1NPD1cEb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_square_subsequent_mask(sz):\n",
        "    mask = (torch.triu(torch.ones((sz, sz), device=device)) == 1).transpose(0, 1)\n",
        "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "    return mask.to(device)\n",
        "\n",
        "\n",
        "def create_mask(src, tgt):\n",
        "    src_seq_len = src.shape[0]\n",
        "    tgt_seq_len = tgt.shape[0]\n",
        "\n",
        "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
        "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=device).type(torch.bool)\n",
        "\n",
        "    src_padding_mask = (src == tokenizer_src.pad_token_id).transpose(0, 1)\n",
        "    tgt_padding_mask = (tgt == tokenizer_tgt.pad_token_id).transpose(0, 1)\n",
        "    return src_mask.to(device), tgt_mask.to(device), src_padding_mask.to(device), tgt_padding_mask.to(device)"
      ],
      "metadata": {
        "id": "lPEnR9_0ENgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_square_subsequent_mask(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqXHD6MW25BE",
        "outputId": "eb5d182e-b667-40d1-b2fc-246894f7b196",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1735159770953,
          "user_tz": -540,
          "elapsed": 292,
          "user": {
            "displayName": "Jason SJ Yim",
            "userId": "00695299170620821850"
          }
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., -inf, -inf],\n",
              "        [0., 0., -inf],\n",
              "        [0., 0., 0.]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's Intiate Model and Conduct Training\n",
        "1. `nn.CrossEntropyLoss(ignore_index=tokenizer_tgt.pad_token_id)`\n",
        "  * We are asking loss function to ignore where it is padded token\n",
        "2. `tgt_out = tgt[1:, :]`\n",
        "\n",
        "  * we are removing the first token of the target sequence, since it corresponds to the special start-of-sentence token <sos>. By removing this token, we obtain a new tensor tgt_out that contains the remaining tokens of the target sequence, which will be used as input to the decoder during training. This is because during training, we want the model to learn to generate the target sequence given the input source sequence, without being provided with the start-of-sentence token\n",
        "\n",
        "3. ` loss=criterion(output.reshape(-1, output.shape[-1]), tgt_out.reshape(-1))\n",
        "`\n",
        "  * The output tensor has shape [tgt_seq_len - 1, batch_size, tgt_vocab_size], which means it has 3 dimensions. To calculate the loss, we need to reshape it to a 2D tensor of shape [(tgt_seq_len - 1) * batch_size, tgt_vocab_size].\n",
        "\n",
        "  * Similarly, tgt_out tensor has shape [tgt_seq_len - 1, batch_size], but to calculate the loss, we need to flatten it into a 1D tensor of shape [(tgt_seq_len - 1) * batch_size]."
      ],
      "metadata": {
        "id": "q-iOyj7a5kBG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### 역자 주: 다음 코드는 예시로서 지금까지 해 온 코드와는 입출력 차원이 맞지 않는 등 에러가 발생할 수 있습니다.\n",
        "\"\"\"\n",
        "input_dim = 50\n",
        "output_dim=50\n",
        "emb_size=512\n",
        "nhead = 8\n",
        "num_encoder_layers =num_decoder_layers= 3\n",
        "\n",
        "model = TransformerModel(num_encoder_layers, num_decoder_layers, emb_size, nhead, src_vocab_size=tokenizer_src.vocab_size, tgt_vocab_size=tokenizer_tgt.vocab_size, dim_feedforward=512).to(device)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 1\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=tokenizer_tgt.pad_token_id)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "model.train()\n",
        "losses = 0\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (src_ids, tgt_ids) in enumerate(dataloader):\n",
        "        src=src_ids.to(device)\n",
        "        tgt=tgt_ids.to(device)\n",
        "        tgt_input = tgt[:-1, :]\n",
        "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
        "        # (self, src, trg, src_mask=None, src_padding_mask=None,trg_mask=None, trg_padding_mask=None, memory_key_padding_mask=None)\n",
        "        output=model(src, tgt_input, src_mask, src_padding_mask,tgt_mask, tgt_padding_mask, src_padding_mask)\n",
        "        optimizer.zero_grad()\n",
        "        tgt_out = tgt[1:, :]\n",
        "        loss=criterion(output.reshape(-1, output.shape[-1]), tgt_out.reshape(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if i%100==0:\n",
        "          print('epoch ', epoch, 'batch ', i, ' loss ', loss)\n",
        "        losses=loss.item()\n",
        "    print( losses / float(len(list(dataloader))))\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "D9MBgnND3HqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analysis:\n",
        "The above code is a simplified version of a machine translation model. In future chapters, we will explore more advanced models."
      ],
      "metadata": {
        "id": "RwnMVKAX_wWQ"
      }
    }
  ]
}